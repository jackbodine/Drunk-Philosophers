{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31273f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef2a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drunk Philosophers\n",
      " What's new, Socrates, to make you leave your usual haunts in the Lyceum and spend your time here by the king archon's court? Surely you are not prosecuting anyone before the king archon as I am? The Athenians do not call this a prosecution but an indictment, Euthyphro. What is this you say? Someone must have indicted you, for you are not going to tell me that you have indicted someone else. But someone else has indicted you? I do not really know him myself, Euthyphro. He is apparently young and unknown. They call him Meletus, I believe. He belongs to the Pitthean deme, if you know anyone from that deme called Meletus, with long hair, not much of a beard, and a rather aquiline nose. I don't know him, Socrates. What charge does he bring against you? A not ignoble one I think , for it is no small thing for a young man to have knowledge of such an important subject. He says he knows how our young men are corrupted and who corrupts them. He is likely to be wise, and when he sees my ignorance corrupting his contemporaries, he proceeds to accuse me to the city as to their mother. I think he is the only one of our public men to start out the right way, for it is right to care first that the young should be as good as possible, just as a good farmer is likely to take care of the young plants first, and of the others later. So, too, Meletus first gets rid of us who corrupt the young shoots, as he says, and then afterwards he will obviously take care of the older ones and become a source of great blessings for the city, as seems likely to happen to one who started out this way. I could wish this were true, Socrates, but I fear the opposite may happen. He seems to me to start out by harming the very heart of Euthyphro the city by attempting to wrong you. Tell me, what does he say you do to corrupt the young? Strange things, to hear him tell it, for he says that I am a maker of gods, and on the ground that I create new gods while not believing in the old gods, he has indicted m\n"
     ]
    }
   ],
   "source": [
    "print(\"Drunk Philosophers\")\n",
    "\n",
    "data_raw = pd.read_csv(\"./data/philosophy_data.csv\")\n",
    "data_raw = data_raw.drop(['sentence_spacy', 'original_publication_date', 'corpus_edition_date', 'sentence_length', 'sentence_lowered', 'lemmatized_str'], axis=1)\n",
    "philosophers = list(dict.fromkeys(data_raw['author'].tolist()))\n",
    "\n",
    "selected_data = data_raw.loc[data_raw['author'] == \"Plato\"]\n",
    "text = ' '.join(selected_data['sentence_str'].tolist())\n",
    "\n",
    "print(text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1949ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackbodine/opt/anaconda3/envs/DeepLearning_Env/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jackbodine/opt/anaconda3/envs/DeepLearning_Env/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 11:51:24.656392: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "2022-04-19 11:51:24.662182: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "2022-04-19 11:51:24.677877: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] model_pruner failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss_2/dense_3_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss_2/dense_3_loss/categorical_crossentropy/weighted_loss/concat'.\n",
      "2022-04-19 11:51:24.696539: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss_2/dense_3_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss_2/dense_3_loss/categorical_crossentropy/weighted_loss/concat'.\n",
      "2022-04-19 11:51:24.699929: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.\n",
      "2022-04-19 11:51:24.702993: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "2022-04-19 11:51:24.706984: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "2022-04-19 11:51:24.716920: W tensorflow/core/common_runtime/process_function_library_runtime.cc:675] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889615/889615 [==============================] - 395s 443us/step - loss: 1.7937 - categorical_crossentropy: 1.7937 - accuracy: 0.4580\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" trib\"\n",
      " tribe one it is soul s or same to then the for that was accept then it one who case the good of the same to say, and large of the many the good and a man who was an accounter to be a state of the law any other of the soul so the other that if the greater is it is it is a particular with who case and poets the only in his one are they are a man which the many. It see the one doubles to the same present\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "seqlen = 5\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "    \n",
    "    # Q5: What does diversity do?\n",
    "    diversity = 0.5\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + seqlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[print_callback])\n",
    "\n",
    "model.save(\"models/Plato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc49262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
